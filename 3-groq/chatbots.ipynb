{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3ad8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c454a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002C8962BBEB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002C8962F5360>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq \n",
    "model = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae91761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's awesome! 👋\\n\\nWhat kind of software engineering do you do?  Web development, mobile apps, game development, something else entirely?  \\n\\nI'm always interested in learning more about what people do in this field.  Maybe you can tell me about a project you're working on or something you're excited about in the world of software engineering right now. 😊\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 17, 'total_tokens': 99, 'completion_time': 0.149090909, 'prompt_time': 0.002002926, 'queue_time': 0.243375954, 'total_time': 0.151093835}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--84517848-a492-401e-a5dc-ae55e2c75ceb-0', usage_metadata={'input_tokens': 17, 'output_tokens': 82, 'total_tokens': 99})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, I'm a software engineer\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2274b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory \n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory \n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store: \n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991f12ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chatbot1\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a167c118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi John Doe! It's nice to finally know your name and profession.  Software engineering is a fascinating field. What kind of software do you specialize in? 💻  \\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 249, 'total_tokens': 289, 'completion_time': 0.072727273, 'prompt_time': 0.011849409, 'queue_time': 0.24484713, 'total_time': 0.084576682}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--7ff97c61-e0f3-4591-a2d9-10868aed0686-0', usage_metadata={'input_tokens': 249, 'output_tokens': 40, 'total_tokens': 289})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am John Doe. I work as a software engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f7e9593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You said your profession is software engineering, John Doe. \\n\\nI remember what you tell me!  \\n\\nIs there anything else you'd like to chat about?  \\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my profesion?\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7ea12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 14, 'total_tokens': 57, 'completion_time': 0.078181818, 'prompt_time': 0.001913477, 'queue_time': 0.244024152, 'total_time': 0.080095295}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--810bcdae-40f8-4185-bf0d-0aa83498642b-0', usage_metadata={'input_tokens': 14, 'output_tokens': 43, 'total_tokens': 57})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chatbot2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de862f35",
   "metadata": {},
   "source": [
    "### Chat prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b751b353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000002054613DAB0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020557EDF9D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020557F14E80>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq \n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder \n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "879662a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "chain.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, I am a software tester\")]\n",
    "})\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d33b4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! That's great. I can be quite helpful for a Solution Architect. \\n\\nHow can I assist you today? \\n\\nDo you need help with:\\n\\n* **Brainstorming solutions for a particular problem?**\\n* **Comparing different technologies or architectures?**\\n* **Documenting a solution design?**\\n* **Understanding complex technical concepts?**\\n* **Generating code snippets or scripts?**\\n\\nJust let me know what's on your mind and I'll do my best to help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 22, 'total_tokens': 132, 'completion_time': 0.2, 'prompt_time': 0.002179099, 'queue_time': 0.24803179100000003, 'total_time': 0.202179099}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--0dfed5f3-032d-45d2-ab86-a2dffa83cf44-0', usage_metadata={'input_tokens': 22, 'output_tokens': 110, 'total_tokens': 132})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chatbot3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, I am a Solution Architect\")],\n",
    "    config = config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45746f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते!  मी एक सहायक बनून येथे आहे. \\n\\nतुम्ही विक्री अधिकारी आहात हे मला माहित आहे. मला काय मदत करावी लागेल? \\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add more complexity \n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"msg\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model \n",
    "\n",
    "resp = chain.invoke({\n",
    "    \"msg\": [HumanMessage(content=\"Hi, I am a Sales executive\")],\n",
    "    \"language\": \"Hindi\"\n",
    "})\n",
    "resp.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820c9e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते! दिल्ली से एक सेल्स एक्जीक्यूटिव होने के नाते आपका स्वागत है!  \\n\\nआप मुझे कैसे मदद कर सकते हैं? \\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history,\n",
    "    input_messages_key=\"msg\"\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"chatbot-test\"}}\n",
    "resp = with_message_history.invoke(\n",
    "    {\n",
    "        \"msg\": [HumanMessage(content=\"Hi, I am a Sales executive from Delhi\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "784fc892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आपने खुद ही बताया था कि आप एक सेल्स एक्जीक्यूटिव हैं।  \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"msg\": [HumanMessage(content=\"What is my profession?\")],\n",
    "        \"language\":\"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c538e3b",
   "metadata": {},
   "source": [
    "### Managing Chat conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d82d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Code\\Python\\langchain-app\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Code\\Python\\langchain-app\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\indra\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, I am Bob', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi Bob', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 5 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='7', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Paris', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"How's the weather?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hot and humid', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    # allow_partials=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "message = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi, I am Bob\"),\n",
    "    AIMessage(content=\"Hi Bob\"),\n",
    "    HumanMessage(content=\"What is 5 + 2\"),\n",
    "    AIMessage(content=\"7\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "    AIMessage(content=\"Paris\"),\n",
    "    HumanMessage(content=\"How's the weather?\"),\n",
    "    AIMessage(content=\"Hot and humid\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    AIMessage(content=\"No problem\"),\n",
    "]\n",
    "trimmer.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7377c9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='आपको मैंने बताया था की मौसम गर्म और आर्द्र है। \\n\\n\\n\\nLet me know if you have any other questions!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 119, 'total_tokens': 151, 'completion_time': 0.058181818, 'prompt_time': 0.005351817, 'queue_time': 0.255038202, 'total_time': 0.063533635}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ff086762-418e-4373-a4c6-44518d02bb5c-0', usage_metadata={'input_tokens': 119, 'output_tokens': 32, 'total_tokens': 151})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"msg\") | trimmer)\n",
    "    | prompt \n",
    "    | model\n",
    ")\n",
    "chain.invoke({\n",
    "    \"msg\": message + [HumanMessage(content=\"What answer did I get about the weather?\")],\n",
    "    \"language\": \"Hindi\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3598e9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आपने पूछा था कि मौसम कैसा है। \\n\\n(You asked how the weather is.)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history,\n",
    "    input_messages_key=\"msg\"\n",
    ")\n",
    "config = {\"configurable\": {\"session_id\": \"chatbot-history\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"msg\": message + [HumanMessage(content=\"What did I ask about the weather?\")],\n",
    "        \"language\": \"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
